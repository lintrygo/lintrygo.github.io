<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[go和Java对比（基本语法）]]></title>
    <url>%2F2024%2F04%2F14%2Fgo%E5%92%8Cjava%E5%AF%B9%E6%AF%94%EF%BC%88%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一 、基础语法Golang: 编码风格及可见域规则严格且简单；Java: 来说层次接口清晰、规范 1、变量a、变量声明及使用在Java中：变量可以声明了却不使用 public static String toString(int num) { int data = num; return String.valueOf(num); } Golang中：声明的变量必须被使用（否则会编译报错），否则需要使用_来替代掉变量名，表明该变量不会使用到 func toString(num int) string { data := num // data没有使用者，无法编译 return num } func toString(num int) string { _ := num // 正常编译 return num } b、变量声明及初始化在Java中：如果在方法内部声明一个变量但不初始化，在使用时会出现编译错误； public void compareVariable() { int age; Object object; System.out.println(age); // 编译错误 System.out.println(object); // 编译错误 } 在Golang中：对于基本类型来讲，声明即初始化，默认为0;对于引用类型，声明则初始化为nil。 func compareVariable() { var age int var hashMap *map[string]int fmt.Println(num) // num = 0 fmt.Println(hashMap) // &amp;hashMap== nil }。 2、作用域规则Java: 对方法、变量及类的可见域规则是通过private、protected、public关键字来控制的 Golang: 控制可见域的方式只有一个，当字段首字母开头是大写时说明其是对外可见的、小写时只对包内成员可见。 3、逗号 ok 模式在使用Golang编写代码的过程中，许多方法经常在一个表达式返回2个参数时使用这种模式：,ok，第一个参数是一个值或者nil，第二个参数是true/false或者一个错误error。在一个需要赋值的if条件语句中，使用这种模式去检测第二个参数值会让代码显得优雅简洁。这种模式在Golang编码规范中非常重要。这是Golang自身的函数多返回值特性的体现。例如： if _, ok := conditionMap[&quot;page&quot;]; ok { // } 4、结构体、函数以及方法a、结构体声明及使用在Golang中区别与Java最显著的一点是，Golang不存在“类”这个概念，组织数据实体的结构在Golang中被称为结构体。函数可以脱离“类”而存在，函数可以依赖于结构体来调用或者依赖于包名调用。Golang中的结构体放弃了继承、实现等多态概念，结构体之间可使用组合来达到复用方法或者字段的效果 Golang 声明一个结构体并使用： // User 定义User结构体 type User struct { Name string Age int } // 使用一个结构体 func main() { personPoint := new(User) // 通过new方法创建结构体指针 person1 := User{} // 通过Person{}创建默认字段的结构体 person2 := User{ Name: &quot;zwh5&quot;, Age: zwh5, } fmt.Println(personPoint) // &amp;{ 0 } fmt.Println(person1) // { 0 } fmt.Println(person2) // {xiaoHong 21 } } Java声明实体并使用： class User { private String name; private int age; public User(String name, int age) { this.name = name; this.age = age; } public void setName(String name) { this.name = name; } public void setAge(int age) { this.age = age; } public String getName() { return name; } public int getAge() { return age; } public String print() { return &quot;{name = &quot; + name + &quot;,age = &quot; + age + &quot;}&quot;; } } public class Demo { public static void main(String[] args) { User user = new User(&quot;zwh5&quot;, 28); System.out.println(&quot;user信息：&quot; + user.print()); } } //执行结果 user信息：{name = zwh5,age = 28} b、函数和方法的区别在Java中：所有的“函数”都是基于“类”这个概念构建的，也就是只有在“类”中才会包含所谓的“函数”，这里的“函数”被称为“方法”，可见上方声明实体并使用。 在Golang中：“函数”和“方法”的最基本区别是：函数不基于结构体而是基于包名调用，方法基于结构体调用。如下实例： package entity import &quot;fmt&quot; type User struct { Name string Age int } // User结构体/指针可调用的&quot;方法&quot;，属于User结构体 func (user *User) Solve() { fmt.Println(user) } // 任何地方都可调用的&quot;函数&quot;，不属于任何结构体，可通过entity.Solve调用 func Solve(user *User) { fmt.Println(user) } func main() { userPoint := new(entity.User) // 通过new方法创建结构体指针 entity.Solve(userPoint) // 函数调用 userPoint.Solve() // 方法调用 } 5、值类型、引用类型以及指针Java：在Java中不存在显式的指针操作；8种基本数据类型是值类型，数组和对象属于引用类型。Golang：而Golang中存在显式的指针操作，但是Golang的指针不像C那么复杂，不能进行指针运算；所有的基本类型都属于值类型，但是有几个类型比较特殊，表现出引用类型的特征，分别是slice、map、channel、interface，除赋值以外它们都可以当做引用类型来使用，因此当我们这样做时,可以直接使用变量本身而不用指针。注：slice与数组的区别为是否有固定长度，slice无固定长度，数组有固定长度。值得注意的是，在Golang中，只有同长度、同类型的数组才可视为“同一类型”，譬如[]int和[3]int则会被视为不同的类型，这在参数传递的时候会造成编译错误。 a、数组对比在Java中：当向方法中传递数组时，可以直接通过该传入的数组修改原数组内部值（浅拷贝）。在Golang中：则有两种情况：在不限定数组长度(为slice)时也直接改变原数组的值，当限定数组长度时会完全复制出一份副本来进行修改（深拷贝）： Java的数组实践: public static void main(String[] args) { int[] array = {1, 2, 3}; change(array); System.out.println(Arrays.toString(array)); // -1,2,3 } private static void change(int[] array) { array[0] = -1; } Golang的数组实践: // 不限定长度（即slice）: func main() { var array = []int{1, 2, 3} change(array) fmt.Println(array) // [-1 2 3] } func change(array []int) { array[0] = -1 } // 限定长度（即数组）： func main() { var array = [3]int{1, 2, 3} change(array) fmt.Println(array) //[1 2 3] } func change(array [3]int) { array[0] = -1 } b、对象对比在Golang中：传入函数参数的是原对象的一个全新的copy（有自己的内存地址）;go对象之间赋值是把对象内存的 内容（字段值等） copy过去，所以才会看到globalUser修改前后的地址不变，但是对象的内容变了。在Java中：传入函数参数的是原对象的引用的copy（指向的是同样的内存地址）; Java对象之间的赋值是把对象的引用 copy过去，因为引用指向的地址变了，所以对象的内容也变了。 Golang的对象实践： //User 定义User结构体 type User struct { Name string Age int } // 定义一个全局的User var globalUser = User { &quot;xiaoming&quot;, 28, } // modifyUser 定义一个函数，参数为User结构体“对象”，将全局globalUser指向传递过来的User结构体“对象” func modifyUser(user User) { fmt.Printf(&quot;参数user的地址 = %p\n&quot;,&amp;user) fmt.Printf(&quot;globalUser修改前的地址 = %p\n&quot;,&amp;globalUser) fmt.Println(&quot;globalUser修改前 = &quot;,globalUser) // 修改指向 globalUser = user fmt.Printf(&quot;globalUser修改后的地址 = %p\n&quot;,&amp;globalUser) fmt.Println(&quot;globalUser修改后 = &quot;,globalUser) } func main() { var u User = User { &quot;xiaohong&quot;, 29, } fmt.Printf(&quot;将要传递的参数u的地址 = %p\n&quot;,&amp;u) modifyUser(u) } // 执行结果 将要传递的参数u的地址 = 0xc0000ac018 参数user的地址 = 0xc0000ac030 globalUser修改前的地址 = 0x113a270 globalUser修改前 = {xiaoming 28} globalUser修改后的地址 = 0x113a270 globalUuser修改后 = {xiaohong 29} Java的对象实践验证： class User { private String name; private int age; public User(String name, int age) { this.name = name; this.age = age; } public void setName(String name) { this.name = name; } public void setAge(int age) { this.age = age; } public String getName() { return name; } public int getAge() { return age; } public String print() { return &quot;{name = &quot; + name + &quot;,age = &quot; + age + &quot;}&quot;; } } public class Demo { private static User globalUser = new User(&quot;xiaoming&quot;,28); public static void modifyUser(User user) { System.out.println(&quot;参数globalUser的地址 = &quot; + user); System.out.println(&quot;globalUser修改前的地址 = &quot; + globalUser); System.out.println(&quot;globalUser修改前 = &quot; + globalUser.print()); globalUser = user; System.out.println(&quot;globalUser修改后的地址 = &quot; + globalUser); System.out.println(&quot;globalUser修改后 = &quot; + globalUser.print()); } public static void main(String[] args) { User user = new User(&quot;xiaohong&quot;, 29); System.out.println(&quot;将要传递的参数user的地址 = &quot; + user); modifyUser(user); } } //执行结果 将要传递的参数user的地址 = com.example.demo.User@5abca1e0 参数globalUser的地址 = com.example.demo.User@5abca1e0 globalUser修改前的地址 = com.example.demo.User@2286778 globalUser修改前 = {name = xiaoming,age = 28} globalUser修改后的地址 = com.example.demo.User@5abca1e0 globalUser修改后 = {name = xiaohong,age = 29} c、指针的区别在Java中：如果传递了引用类型（对象、数组等）会复制其指针进行传递在Golang中：必须要显式传递Person的指针，不然只是传递了该对象的一个副本。 Golang的指针： // User 定义User结构体 type User struct { Name string Age int } func main() { p1 := User{ Name: &quot;xiaohong&quot;, Age: 21, } changePerson(p1) fmt.Println(p1.Name) // xiaohong changePersonByPointer(&amp;p1) fmt.Println(p1.Name) // xiaoming } func changePersonByPointer(user *User) { user.Name = &quot;xiaoming&quot; } func changePerson(user User) { user.Name = &quot;xiaoming&quot; }]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[gorm基础学习(一)]]></title>
    <url>%2F2024%2F04%2F14%2Fgorm%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[Gorm 介绍与安装Gorm是一款用于Golang的ORM框架，它提供了丰富的功能，包括模型定义、数据验证、关联查询等。Gorm的设计目标是简洁而强大，使得开发者能够更轻松地进行数据库操作。 一些Gorm的特性包括： 模型定义和操作： 全功能 ORM 关联 (Has One，Has Many，Belongs To，Many To Many，多态，单表继承)Create，Save，Update，Delete，Find 中的钩子方法 支持 Preload、Joins 的预加载 批量插入，FindInBatches，Find/Create with Map，使用 SQL 表达式、Context Valuer 进行 CRUD 复合主键，索引，约束 事务处理和数据库操作： 事务，嵌套事务，Save Point，Rollback To Saved Point Context、预编译模式、DryRun 模式 SQL 构建器，Upsert，数据库锁，Optimizer/Index/Comment Hint，命名参数，子查询 Auto Migration 其他功能： 自定义 Logger 灵活的可扩展插件 API：Database Resolver（多数据库，读写分离）、Prometheus… 每个特性都经过了测试的重重考验 开发者友好 最新版本2.x，比1.x有较大改动，注意:Gorm最新地址为https://github.com/go-gorm/gorm，之前https://github.com/jinzhu/gorm地址为v1旧版本 Gorm 连接数据库快速连接 MySQL12345678910111213141516171819202122232425262728293031323334353637383940package mainimport ( &quot;gorm.io/driver/mysql&quot; &quot;gorm.io/gorm&quot;)type Product struct &#123; gorm.Model Code string Price uint&#125;func main() &#123; dsn := &quot;root:123456@tcp(127.0.0.1:3306)/demo?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot; db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config&#123;&#125;) if err != nil &#123; panic(&quot;failed to connect database&quot;) &#125; // 迁移 schema db.AutoMigrate(&amp;Product&#123;&#125;) // Create db.Create(&amp;Product&#123;Code: &quot;D42&quot;, Price: 100&#125;) // Read var product Product db.First(&amp;product, 1) // 根据整型主键查找 db.First(&amp;product, &quot;code = ?&quot;, &quot;D42&quot;) // 查找 code 字段值为 D42 的记录 // Update - 将 product 的 price 更新为 200 db.Model(&amp;product).Update(&quot;Price&quot;, 200) // Update - 更新多个字段 db.Model(&amp;product).Updates(Product&#123;Price: 200, Code: &quot;F42&quot;&#125;) // 仅更新非零值字段 db.Model(&amp;product).Updates(map[string]interface&#123;&#125;&#123;&quot;Price&quot;: 200, &quot;Code&quot;: &quot;F42&quot;&#125;) // Delete - 删除 product db.Delete(&amp;product, 1)&#125; MySQL数据库配置解析自定义 MySQL 驱动GORM 允许通过 DriverName 选项自定义 MySQL 驱动，例如： 1234567891011121314package mainimport ( _ &quot;example.com/my_mysql_driver&quot; &quot;gorm.io/driver/mysql&quot; &quot;gorm.io/gorm&quot;)func main() &#123; db, err := gorm.Open(mysql.New(mysql.Config&#123; DriverName: &quot;my_mysql_driver&quot;, DSN: &quot;gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8&amp;parseTime=True&amp;loc=Local&quot;, // data source name, 详情参考：https://github.com/go-sql-driver/mysql#dsn-data-source-name &#125;), &amp;gorm.Config&#123;&#125;)&#125; 现有的数据库连接mysqlGORM 允许通过一个现有的数据库连接来初始化 *gorm.DB 123456789101112import ( &quot;database/sql&quot; &quot;gorm.io/driver/mysql&quot; &quot;gorm.io/gorm&quot;)func main() &#123; sqlDB, err := sql.Open(&quot;mysql&quot;, &quot;mydb_dsn&quot;) gormDB, err := gorm.Open(mysql.New(mysql.Config&#123; Conn: sqlDB, &#125;), &amp;gorm.Config&#123;&#125;)&#125; 现有的数据库连接mysql123456789101112import ( &quot;database/sql&quot; &quot;gorm.io/driver/mysql&quot; &quot;gorm.io/gorm&quot;)func main() &#123; sqlDB, err := sql.Open(&quot;mysql&quot;, &quot;mydb_dsn&quot;) gormDB, err := gorm.Open(mysql.New(mysql.Config&#123; Conn: sqlDB, &#125;), &amp;gorm.Config&#123;&#125;)&#125; 连接池GORM 使用 database/sql 来维护连接池 12345678910sqlDB, err := db.DB()// SetMaxIdleConns sets the maximum number of connections in the idle connection pool.sqlDB.SetMaxIdleConns(10)// SetMaxOpenConns sets the maximum number of open connections to the database.sqlDB.SetMaxOpenConns(100)// SetConnMaxLifetime sets the maximum amount of time a connection may be reused.sqlDB.SetConnMaxLifetime(time.Hour)]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[gin基础学习(一)]]></title>
    <url>%2F2024%2F04%2F14%2Fgin%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1、简介1.1. 介绍 Gin是一个golang的微框架，封装比较优雅，API友好，源码注释比较明确，具有快速灵活，容错方便等特点 对于golang而言，web框架的依赖要远比Python，Java之类的要小。自身的net/http足够简单，性能也非常不错 借助框架开发，不仅可以省去很多常用的封装带来的时间，也有助于团队的编码风格和形成规范 安装要安装Gin软件包，您需要安装Go并首先设置Go工作区。 1.首先需要安装Go（需要1.10+版本），然后可以使用下面的Go命令安装Gin。 1go get -u github.com/gin-gonic/gin 2.将其导入您的代码中： 1import "github.com/gin-gonic/gin" 3.（可选）导入net/http。例如，如果使用常量，则需要这样做http.StatusOK。 import “net/http” 2、基本路由 gin 框架中采用的路由库是基于httprouter做的 地址为：https://github.com/julienschmidt/httprouter 后端请求同样分为：GET POST PUT 12345678910111213141516171819202122232425package main import ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;) func main() &#123; // 1.创建路由 r := gin.Default() // 2.绑定路由规则，执行的函数 // gin.Context，封装了request和response r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world!!&quot;) &#125;) // post请求 r.POST(&quot;/post&quot;) // put 请求 r.PUT(&quot;/put&quot;) // 3.监听端口，默认在8080 // Run(&quot;里面不指定端口号默认为8080&quot;) r.Run(&quot;:8001&quot;)&#125;]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[部署go-admin]]></title>
    <url>%2F2024%2F04%2F14%2F%E9%83%A8%E7%BD%B2go-admin%2F</url>
    <content type="text"><![CDATA[部署go-adminnginx 配置12345678910111213141516171819202122server &#123; listen 80; server_name localhost; # 配置前端静态文件目录 location / &#123; index index.html index.htm; root /home/go/src/go-admin/dist; try_files $uri $uri/ /index.html; &#125; # 配置后台go服务api接口服务 代理到8000端口 location ~ ^/api/ &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; rewrite ^/goadminapi/(.*)$ /$1 break; proxy_pass http://127.0.0.1:8000; &#125;&#125;`nginx -t` //测试nginx配置是否正确`nginx -s reload` //重启nginx服务 Shell 脚本打包 go 服务修改配置信息 123456database: # 数据库类型 mysql, sqlite3, postgres, sqlserver # sqlserver: sqlserver://用户名:密码@地址?database=数据库名 driver: mysql # 数据库连接字符串 mysql 缺省信息 charset=utf8&amp;parseTime=True&amp;loc=Local&amp;timeout=1000ms source: root:123456@tcp(127.0.0.1:3306)/go_admin_dev?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&amp;timeout=1000ms 打包命令 12345# 需要一行执行，同时需要看部署服务器是否为linux，是否是amd64还是armSET CGO_ENABLED=0SET GOOS=linuxSET GOARCH=amd64go build -o go-admin main.go 启动脚本 123456#!/bin/bashecho &quot;删除进程&quot;killall go-admin #杀死运行中的go-admin服务进程echo &quot;启动进程&quot;nohup ./go-admin server -c=config/settings.yml &gt;&gt; access.log 2&gt;&amp;1 &amp; #后台启动服务将日志写入access.log文件ps -aux | grep go-admin #查看运行用的进程 上传配置 上传 config 配置到服务器上 1234567891011[root@iZ2ze505h9bgsbp83ct28pZ go-admin]# tree.├── config│ ├── db.sql # 系统初始化配置不建议上传服务器│ ├── rbac_model.conf│ ├── READMEN.md│ ├── settings.dev.yml # 测试环境配置不建议上传服务器│ ├── settings.yml│ └── sqlite.sql # 系统初始化配置不建议上传服务器├── go-admin└── restart.sh 启动服务 12345[root@iZ2ze505h9bgsbp83ct28pZ go-admin]# ./restart.sh删除进程go-admin: 未找到进程启动进程root 4033 0.0 0.0 12324 1080 pts/0 R+ 07:39 0:00 grep go-admin]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[goroutine]]></title>
    <url>%2F2024%2F04%2F13%2Fgoroutine%2F</url>
    <content type="text"><![CDATA[1、goroutine协程并发协程：coroutine。也叫轻量级线程。 与传统的系统级线程和进程相比，协程最大的优势在于“轻量级”。可以轻松创建上万个而不会导致系统资源衰竭。而线程和进程通常很难超过1万个。这也是协程别称“轻量级线程”的原因。 一个线程中可以有任意多个协程，但某一时刻只能有一个协程在运行，多个协程分享该线程分配到的计算机资源。 Go并发Go 在语言级别支持协程，叫goroutine。Go 语言标准库提供的所有系统调用操作（包括所有同步IO操作），都会出让CPU给其他goroutine。这让轻量级线程的切换管理不依赖于系统的线程和进程，也不需要依赖于CPU的核心数量。 Go语言为并发编程而内置的上层API基于顺序通信进程模型CSP(communicating sequential processes)。这就意味着显式锁都是可以避免的，因为Go通过相对安全的通道发送和接受数据以实现同步，这大大地简化了并发程序的编写。 Go语言中的并发程序主要使用两种手段来实现。goroutine和channel。 什么是Goroutineoroutine是Go语言并行设计的核心，有人称之为go程。 Goroutine从量级上看很像协程，它比线程更小，十几个goroutine可能体现在底层就是五六个线程，Go语言内部帮你实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存(大概是4~5KB)，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千上万个并发任务。goroutine比thread更易用、更高效、更轻便。 一般情况下，一个普通计算机跑几十个线程就有点负载过大了，但是同样的机器却可以轻松地让成百上千个goroutine进行资源竞争。 创建Goroutine只需在函数调⽤语句前添加 go 关键字，就可创建并发执⾏单元。开发⼈员无需了解任何执⾏细节，调度器会自动将其安排到合适的系统线程上执行。 在并发编程中，我们通常想将一个过程切分成几块，然后让每个goroutine各自负责一块工作，当一个程序启动时，主函数在一个单独的goroutine中运行，我们叫它main goroutine。新的goroutine会用go语句来创建。而go语言的并发设计，让我们很轻松就可以达成这一目的。 123456789101112131415161718192021222324252627package main import ( &quot;fmt&quot; &quot;time&quot;) func newTask() &#123; i := 0 for &#123; i++ fmt.Printf(&quot;new goroutine: i = %d\n&quot;, i) time.Sleep(1*time.Second) //延时1s &#125;&#125; func main() &#123; //创建一个 goroutine，启动另外一个任务 go newTask() i := 0 //main goroutine 循环打印 for &#123; i++ fmt.Printf(&quot;main goroutine: i = %d\n&quot;, i) time.Sleep(1 * time.Second) //延时1s &#125;&#125; Goroutine特性主goroutine退出后，其它的工作goroutine也会自动退出： 12345678910111213141516171819202122package main import (&quot;fmt&quot;&quot;time&quot;) func newTask() &#123; i := 0 for &#123; i++ fmt.Printf(&quot;new goroutine: i = %d\n&quot;, i) time.Sleep(1 * time.Second) //延时1s &#125;&#125; func main() &#123; //创建一个 goroutine，启动另外一个任务 go newTask() fmt.Println(&quot;main goroutine exit&quot;)&#125; Goexit函数调用 runtime.Goexit() 将立即终止当前 goroutine 执⾏，调度器确保所有已注册 defer 延迟调用被执行。 123456789101112131415161718192021222324package main import (&quot;fmt&quot;&quot;runtime&quot;) func main() &#123; go func() &#123; defer fmt.Println(&quot;A.defer&quot;) func() &#123; defer fmt.Println(&quot;B.defer&quot;) runtime.Goexit() // 终止当前 goroutine, import &quot;runtime&quot; fmt.Println(&quot;B&quot;) // 不会执行 &#125;() fmt.Println(&quot;A&quot;) // 不会执行 &#125;() //不要忘记() //死循环，目的不让主goroutine结束 for &#123; &#125;&#125; 2、channelchannel是Go语言中的一个核心类型，可以把它看成管道。并发核心单元通过它就可以发送或者接收数据进行通讯，这在一定程度上又进一步降低了编程的难度。 channel是一个数据类型，主要用来解决go程的同步问题以及go程之间数据共享（数据传递）的问题。 goroutine运行在相同的地址空间，因此访问共享内存必须做好同步。goroutine 奉行通过通信来共享内存，而不是共享内存来通信。 引⽤类型 channel可用于多个 goroutine 通讯。其内部实现了同步，确保并发安全。 定义channel变量 和map类似，channel也一个对应make创建的底层数据结构的引用。 当我们复制一个channel或用于函数参数传递时，我们只是拷贝了一个channel引用，因此调用者和被调用者将引用同一个channel对象。和其它的引用类型一样，channel的零值也是nil。 定义一个channel时，也需要定义发送到channel的值的类型。channel可以使用内置的make()函数来创建： chan是创建channel所需使用的关键字。Type 代表指定channel收发数据的类型。 12make(chan Type) //等价于make(chan Type, 0)make(chan Type, capacity) 无缓冲的channel 无缓冲的通道（unbuffered channel）是指在接收前没有能力保存任何数据值的通道。 这种类型的通道要求发送goroutine和接收goroutine同时准备好，才能完成发送和接收操作。否则，通道会导致先执行发送或接收操作的 goroutine 阻塞等待。 这种对通道进行发送和接收的交互行为本身就是同步的。其中任意一个操作都无法离开另一个操作单独存在。 阻塞：由于某种原因数据没有到达，当前go程（线程）持续处于等待状态，直到条件满足，才解除阻塞。 同步：在两个或多个go程（线程）间，保持数据内容一致性的机制。 12345678910111213141516171819202122232425262728293031package main import ( &quot;fmt&quot; &quot;time&quot;) func main() &#123; c := make(chan int, 0) //创建无缓冲的通道 c //内置函数 len 返回未被读取的缓冲元素数量，cap 返回缓冲区大小 fmt.Printf(&quot;len(c)=%d, cap(c)=%d\n&quot;, len(c), cap(c)) go func() &#123; defer fmt.Println(&quot;子go程结束&quot;) for i := 0; i &lt; 3; i++ &#123; c &lt;- i fmt.Printf(&quot;子go程正在运行[%d]: len(c)=%d, cap(c)=%d\n&quot;, i, len(c), cap(c)) &#125; &#125;() time.Sleep(2 * time.Second) //延时2s for i := 0; i &lt; 3; i++ &#123; num := &lt;-c //从c中接收数据，并赋值给num fmt.Println(&quot;num = &quot;, num) &#125; fmt.Println(&quot;main进程结束&quot;)&#125; 有缓冲的channel 有缓冲的通道（buffered channel）是一种在被接收前能存储一个或者多个数据值的通道。 这种类型的通道并不强制要求 goroutine 之间必须同时完成发送和接收。通道会阻塞发送和接收动作的条件也不同。 只有通道中没有要接收的值时，接收动作才会阻塞。 只有通道没有可用缓冲区容纳被发送的值时，发送动作才会阻塞。 这导致有缓冲的通道和无缓冲的通道之间的一个很大的不同：无缓冲的通道保证进行发送和接收的 goroutine 会在同一时间进行数据交换；有缓冲的通道没有这种保证。 12345678910111213141516171819202122func main() &#123; c := make(chan int, 3) //带缓冲的通道 //内置函数 len 返回未被读取的缓冲元素数量， cap 返回缓冲区大小 fmt.Printf(&quot;len(c)=%d, cap(c)=%d\n&quot;, len(c), cap(c)) go func() &#123; defer fmt.Println(&quot;子go程结束&quot;) for i := 0; i &lt; 3; i++ &#123; c &lt;- i fmt.Printf(&quot;子go程正在运行[%d]: len(c)=%d, cap(c)=%d\n&quot;, i, len(c), cap(c)) &#125; &#125;() time.Sleep(2 * time.Second) //延时2s for i := 0; i &lt; 3; i++ &#123; num := &lt;-c //从c中接收数据，并赋值给num fmt.Println(&quot;num = &quot;, num) &#125; fmt.Println(&quot;main进程结束&quot;)&#125; 3、Selectselect作用 Go里面提供了一个关键字select，通过select可以监听channel上的数据流动。 有时候我们希望能够借助channel发送或接收数据，并避免因为发送或者接收导致的阻塞，尤其是当channel没有准备好写或者读时。select语句就可以实现这样的功能。 select的用法与switch语言非常类似，由select开始一个新的选择块，每个选择条件由case语句来描述。 与switch语句相比，select有比较多的限制，其中最大的一条限制就是每个case语句里必须是一个IO操作，大致的结构如下： 12345678select &#123;case &lt;- chan1: // 如果chan1成功读到数据，则进行该case处理语句case chan2 &lt;- 1: // 如果成功向chan2写入数据，则进行该case处理语句default: // 如果上面都没有成功，则进入default处理流程&#125; 在一个select语句中，Go语言会按顺序从头至尾评估每一个发送和接收的语句。 如果其中的任意一语句可以继续执行(即没有被阻塞)，那么就从那些可以执行的语句中任意选择一条来使用。 如果没有任意一条语句可以执行(即所有的通道都被阻塞)，那么有两种可能的情况： l 如果给出了default语句，那么就会执行default语句，同时程序的执行会从select语句后的语句中恢复。 l 如果没有default语句，那么select语句将被阻塞，直到至少有一个通信可以进行下去。 1234567891011121314151617181920212223242526272829303132package main import ( &quot;fmt&quot;) func fibonacci(c, quit chan int) &#123; x, y := 1, 1 for &#123; select &#123; case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;quit&quot;) return &#125; &#125;&#125; func main() &#123; c := make(chan int) quit := make(chan int) go func() &#123; for i := 0; i &lt; 6; i++ &#123; fmt.Println(&lt;-c) &#125; quit &lt;- 0 &#125;() fibonacci(c, quit)&#125;]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[slice]]></title>
    <url>%2F2024%2F04%2F13%2Fslice%E5%92%8Cmap%2F</url>
    <content type="text"><![CDATA[sliceo 语言切片是对数组的抽象。 Go 数组的长度不可改变，在特定场景中这样的集合就不太适用，Go中提供了一种灵活，功能强悍的内置类型切片(“动态数组”),与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大。 定义切片切片初始化 1s :=[] int &#123;1,2,3 &#125; 直接初始化切片，[]表示是切片类型，{1,2,3}初始化值依次是1,2,3.其cap=len=3 1s := arr[:] 初始化切片s,是数组arr的引用 1s := arr[startIndex:endIndex] len() 和 cap() 函数切片是可索引的，并且可以由 len() 方法获取长度。 切片提供了计算容量的方法 cap() 可以测量切片最长可以达到多少。 以下为具体实例： 1234567891011121314151617package mainimport &quot;fmt&quot;func main() &#123; var numbers = make([]int,3,5) printSlice(numbers)&#125;func printSlice(x []int)&#123; fmt.Printf(&quot;len=%d cap=%d slice=%v\n&quot;,len(x),cap(x),x)&#125; append() 和 copy() 函数如果想增加切片的容量，我们必须创建一个新的更大的切片并把原分片的内容都拷贝过来。 下面的代码描述了从拷贝切片的 copy 方法和向切片追加新元素的 append 方法。 123456789101112131415161718192021222324252627282930313233343536373839package mainimport &quot;fmt&quot;func main() &#123; var numbers []int printSlice(numbers) /* 允许追加空切片 */ numbers = append(numbers, 0) printSlice(numbers) /* 向切片添加一个元素 */ numbers = append(numbers, 1) printSlice(numbers) /* 同时添加多个元素 */ numbers = append(numbers, 2,3,4) printSlice(numbers) /* 创建切片 numbers1 是之前切片的两倍容量*/ numbers1 := make([]int, len(numbers), (cap(numbers))*2) /* 拷贝 numbers 的内容到 numbers1 */ copy(numbers1,numbers) printSlice(numbers1) &#125;func printSlice(x []int)&#123; fmt.Printf(&quot;len=%d cap=%d slice=%v\n&quot;,len(x),cap(x),x)&#125; mapmap和slice类似，只不过是数据结构不同，下面是map的一些声明方式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;fmt&quot;)func main() &#123; //第一种声明 var test1 map[string]string //在使用map前，需要先make，make的作用就是给map分配数据空间 test1 = make(map[string]string, 10) test1[&quot;one&quot;] = &quot;php&quot; test1[&quot;two&quot;] = &quot;golang&quot; test1[&quot;three&quot;] = &quot;java&quot; fmt.Println(test1) //map[two:golang three:java one:php] //第二种声明 test2 := make(map[string]string) test2[&quot;one&quot;] = &quot;php&quot; test2[&quot;two&quot;] = &quot;golang&quot; test2[&quot;three&quot;] = &quot;java&quot; fmt.Println(test2) //map[one:php two:golang three:java] //第三种声明 test3 := map[string]string&#123; &quot;one&quot; : &quot;php&quot;, &quot;two&quot; : &quot;golang&quot;, &quot;three&quot; : &quot;java&quot;, &#125; fmt.Println(test3) //map[one:php two:golang three:java] language := make(map[string]map[string]string) language[&quot;php&quot;] = make(map[string]string, 2) language[&quot;php&quot;][&quot;id&quot;] = &quot;1&quot; language[&quot;php&quot;][&quot;desc&quot;] = &quot;php是世界上最美的语言&quot; language[&quot;golang&quot;] = make(map[string]string, 2) language[&quot;golang&quot;][&quot;id&quot;] = &quot;2&quot; language[&quot;golang&quot;][&quot;desc&quot;] = &quot;golang抗并发非常good&quot; fmt.Println(language) //map[php:map[id:1 desc:php是世界上最美的语言] golang:map[id:2 desc:golang抗并发非常good]] //增删改查 // val, key := language[&quot;php&quot;] //查找是否有php这个子元素 // if key &#123; // fmt.Printf(&quot;%v&quot;, val) // &#125; else &#123; // fmt.Printf(&quot;no&quot;); // &#125; //language[&quot;php&quot;][&quot;id&quot;] = &quot;3&quot; //修改了php子元素的id值 //language[&quot;php&quot;][&quot;nickname&quot;] = &quot;啪啪啪&quot; //增加php元素里的nickname值 //delete(language, &quot;php&quot;) //删除了php子元素 fmt.Println(language)&#125;]]></content>
      <categories>
        <category>go</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式事务]]></title>
    <url>%2F2023%2F07%2F05%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[本地事务只在一个数据库操作，不会有分布式事务问题 特性（ACID）： 原子性：一系列操作不可拆分，要么同时成功，要么同时失败 一致性：数据在事务的前后，业务整体一致 隔离性：事务之间相互隔离 永久性：一旦事务成功，数据一定会落盘数据库 事务隔离级别 读未提交（会有脏读问题） 读已提交 （不可重复读） 可重复读 串行化 事务传播行为REQUIREDREQUIRED_NEW 事务失效问题同个service方法调用，绕过了代理对象 存在的问题 远程服务失败：远程服务其实成功了，由于网络故等没有返回，导致的订单回滚，库存却扣减 远程服务执行完成，下面的其他方法出现问题，导致已执行的远程请求，肯定不能回滚 CAP定理C: Consistency 一致性A: Avaliavlity可用性P: Partition tolerance分区容错性 不可能同时满足，只能CP或AP raftBASE理论BASE 是 BASE Avaliable(基本可用)，Soft state(软状态) 和 Eventually consistent(最终一致性)三个短语的简写 一致性协议2PC两段提交顾名思义就是要进行两个阶段的提交：第一阶段，准备阶段(投票阶段) ；第二阶段，提交阶段（执行阶段）。 TCCTCC（Try-Confirm-Cancel）又被称补偿事务，TCC与2PC的思想很相似，事务处理流程也很相似，但2PC 是应用于在DB层面，TCC则可以理解为在应用层面的2PC，是需要我们编写业务逻辑来实现。 TCC它的核心思想是：”针对每个操作都要注册一个与其对应的确认（Try）和补偿（Cancel）”。 还拿下单扣库存解释下它的三个操作： Try阶段： 下单时通过Try操作去扣除库存预留资源。 Confirm阶段： 确认执行业务操作，在只预留的资源基础上，发起购买请求。 Cancel阶段： 只要涉及到的相关业务中，有一个业务方预留资源未成功，则取消所有业务资源的预留请求。 seata默认是AT模式 AT模式和XA模式区别XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。XA模式强一致；AT模式最终一致]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HashMap原理]]></title>
    <url>%2F2023%2F01%2F15%2Fhashmap%2F</url>
    <content type="text"><![CDATA[HashMapHashMap(jdk1.7)数据结构:数组+链表 12345678910111213141516171819/** * The default initial capacity - MUST be a power of two. * table(数组)默认初始容量16，必须是2的n次方 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. * table(数组)最大容量2的32次方 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The load factor used when none specified in constructor. * 默认负载因子0.75 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; 懒加载方式，不在构造方法中创建容量，只在第一次put操作中创建。 1234567891011121314151617181920212223242526272829public V put(K key, V value) &#123; //若为空数组,则初始化数组，默认为16 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; //当key为null是,存储位置为table[0]或table[0]的冲突链上 if (key == null) return putForNullKey(value); //计算hash值 int hash = hash(key); //根据hash值,定位在数组中的位置 int i = indexFor(hash, table.length); //循环查找该数组中的链表，查找到，则覆盖，并返回旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //保证并发访问时，若HashMap内部结构发生变化，快速响应失败 modCount++; //新增一个entry addEntry(hash, key, value, i); return null; &#125; 1234567891011121314151617//膨胀数组private void inflateTable(int toSize) &#123; //找到一个大于等于的最接近toSize的二次幂 // Find a power of 2 &gt;= toSize int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); &#125; private static int roundUpToPowerOf2(int number) &#123; // assert number &gt;= 0 : &quot;number must be non-negative&quot;; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;&#125; 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 12345//通过hash值定位到数组位置,哈希值和数组长度&amp;运算。static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1);&#125; hashmap为什么数组长度是2的幂次方为了能让HashMap存取高效，尽量减少碰撞，也就是要尽量把数据分配均匀。首先想到的是取余运算即 hash%length，取余操作中如果除数是2的幂次则等价于其除数减一的与操作，也就是说hash%length=hash&amp;(length-1)，对于%运算来说，&amp;运算效率更高，故解释了hashmap为什么长度是的n次幂 为什么&amp;效率更高 因为位运算直接对内存数据进行操作，不需要转成十进制，所以位运算要比取模运算的效率更高 当length为2的N次方的时候，数据分布均匀，减少冲突 2的n次方-1转换成二进制，值全是1，保证了数据分布均匀；若是奇数，最后一位永远是0，这样，空间的减少会导致碰撞几率的进一步增加，从而就会导致查询速度慢。 hashmap多线程死循环问题在jdk 1.7 中hashmap扩容rehash时，使用头插法，多线程操作可能导致形成循环链表，之后再进件get操作时可能引发死循环，造成cpu 100%。在jdk1.8中，把头插法修改为尾插法，修复了该问题。 具体步骤 hashmap底层结构jdk7：数组+链表 jdk8: 数组+链表或红黑树 为什么使用红黑树 jdk7中，可能由于hash碰撞导致链表会很长，造成查询效率会低；在jdk8中，当链表长度大于等于8且元素个数大于64时会转换成红黑树，查询效率由O(n)提升到O(logn) hashmap重要参数初始容量: 创建哈希表(数组)时桶的数量，默认为 16 负载因子: 临界值 = 数组容量*负载因子，当超过临界值时，会自动扩容，还需要对原来元素进行rehash，分配到不同桶中。 hash算法jdk8: (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) ，相当于hashcode的高16位和低16位异或运算 可以将高低位二进制特征混合起来；异或运算能更好的保留各部分的特征]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[P转M(0605微课向上管理)]]></title>
    <url>%2F2022%2F06%2F05%2FP%E8%BD%ACM(0605%E5%BE%AE%E8%AF%BE%E5%90%91%E4%B8%8A%E7%AE%A1%E7%90%86)%2F</url>
    <content type="text"><![CDATA[激励你的领导领导也需要”被看见”，反馈即激励 典型话术上次您支出的xx问题，我最近做了一些尝试/落实，我有xx发现/收获 向你的领导保持战略透明度领导也需要安全感 为什么领导喜欢任用前秘书 主动提高自己的透明度，主动降低别人跟你合作的”心理成本” 典型话术有个事儿一直没有机会说，其实，我曾经有段时间特别怕向您汇报，因为xxx 典型话术昨天您派我去办的那个事儿，结果是xxx，不过过程中有个情况拿不准，可能需要跟您同步下 闭环能力不是做完了才叫闭环，闭环是管理对方的期待 我们通常以为，闭环是为了给别人一个交代。其实不是，它甚至也不是为了给自己一个交代，而是给未来一个交代。 成为你领导的外挂把自己作为方法，好的领导关系是协同进化，承包对方能力圈的一部分。 典型话术这块工作您就交给我吧，我负全责，过程中有问题我随时向您汇报。 向上沟通隐藏技能发展同盟军，怎么和上级身边的人相处。 把他们当成专业人士来尊重 把领导还原成人，渴望被看见，渴望被认同。]]></content>
      <categories>
        <category>P转M</category>
      </categories>
      <tags>
        <tag>向上管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[P转M(0528微课——目标分解与落地)]]></title>
    <url>%2F2022%2F05%2F28%2FP%E8%BD%ACM(0528%E5%BE%AE%E8%AF%BE)%2F</url>
    <content type="text"><![CDATA[如何管事之目标分解与落地定量目标的分析与落地SMART原则 目标-行动措施-解决方案-列计划-做计划 定性目标的分析与目标不能很好量化的。 关键影响因素-&gt;关键评价指标-&gt;关键行动措施。 工作委派与授权问题 工作委派的误区和真相误区： 保姆式委派 派活式委派 真相： 认识匹配 意愿能力 团队授权的误区和真相误区： 放任不管 只要结果 真相： 过程沟通 节点检查 原则 工作委派和授权的应用原则 不要鞭打快牛 （不要一直让一个人做） 不要光凭印象 不要忘记复盘 如何管事之过程跟踪与反馈过程跟踪的节点管理策略 划清路线路 定好节点表 开好节点会 过程管控中的典型障碍与解决方案 计划有变-及时沟通 意外发生-事前预案 责任扯皮-定义标准 过程跟踪与管控的应用原则 责任人主动反馈 未完成信号预警 有问题马上改进]]></content>
      <categories>
        <category>P转M</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[P转M(0522微课)]]></title>
    <url>%2F2022%2F05%2F22%2FP%E8%BD%ACM(0522%E5%BE%AE%E8%AF%BE)%2F</url>
    <content type="text"><![CDATA[如何管人之团队差异化意愿和能力区分 意愿强，能力强：双管奇下 意愿差，能力强：用人所长 意愿强，能力差：重复训练 意愿差，能力差：及时淘汰 动态的眼光看人 阶段用人 如何管人之高效沟通和辅导策略一： 不同的人不同的沟通和辅导方式 意愿强，能力强：认同并激发 意愿差，能力强：倾听并讨论 意愿强，能力差：鼓励并建议 意愿差，能力差：明确并要求 策略二： 意愿强，能力强：面向未来，以他们为主 意愿差，能力强：调整意愿，对症下药 意愿强，能力差：提升能力，时间不够可以帮找导师 意愿差，能力差：限期整改 团队沟通与辅导的场景应用原则 预防大于治疗 选择大于培养：前期招聘环节多参与 团队大于个人 如何管人之有效激励与培养三大典型问题 短期vs长期 奖励vs激励，和钱有关的是奖励，其他方面是激励 结果vs行为 不同员工的培养策略 标杆型员工培养 成长型员工培养 交易型员工培养 应用原则 及时性 差异化 竞争性]]></content>
      <categories>
        <category>P转M</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[P转M(0515微课)]]></title>
    <url>%2F2022%2F05%2F15%2FP%E8%BD%ACM(0515%E5%BE%AE%E8%AF%BE)%2F</url>
    <content type="text"><![CDATA[上下级对新任管理者的期待上级对新任管理者的期待 出业绩 带团队 一条心 下级对新任管理者的期待 长能耐 有前途 被认可 新任管理者对自己的期待 新官上任三把火 最大可能性的展现自己的能力 不要逞强，要想清楚是否是上下级所期待 干出业绩能服众 关键事情和业绩向大家证明 证明上级有眼光 工具与落地：业绩 开会 标杆 创新 培训 复盘 新任管理者的三大成就感1. 管理团队成就感了解团队成员 优化人岗匹配：把正确的人放在正确的位置，最大限度发挥潜力和优势 提升员工的能力提升 2. 管理机制成就感了解频繁出现的业务问题（5个WHY） 倾听员工的抱怨 了解其他部分，其他公司的制度，并借鉴 3. 文化打造成就感团队目标 业务属性 发展阶段：起步阶段，成熟阶段 新任管理者的三大角色定位不要自认为，要回到组织给你定位 不要把自己当成全能保姆，切记全过程参与 不要做替考枪手，员工出问题，不要自己代替解决 业绩驱动者 目标驱动者 制定合理目标 制度驱动者 奖罚，晋升，开会等 文化驱动 团队打造者 以身作则 打造标杆 持续培训 认知，行为，能力的提升 心态凝聚者 沟通面谈 刚发生的时候就解决 关键事件 文化共识 新任管理者的两种风格比较新任管理者就该996 能力强，应该的 当领导的，应该的 做表率，应该的 新任管理者是救火队长 偶尔救火 天天救火 引火烧身 做好基础管理，抓好团队 亲历亲为型新任管理者 精通业务 身先士卒 不能自拔 反思：怎样从孤单英雄到团队英雄 甩手掌柜型新任管理者 抓大放小 给出空间 业务生疏 解决方案：新任管理者管理行为螺旋 刚开始要亲力亲为，后续根据事情情况来判定是否可以使用甩手掌柜模式 团队成员的业务能力不足，如何提升 团队成员的主动性积极性不够，如何培养 怎样从孤单英雄到团队英雄，让更多人参与进来]]></content>
      <categories>
        <category>P转M</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[new对象过程]]></title>
    <url>%2F2021%2F08%2F15%2Fnew%E5%AF%B9%E8%B1%A1%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[假设第一次使用该类，这样可分为两个过程: 加载并初始化类和创建对象 类加载过程使用双亲委派机制。 1. 加载 由类加载器负责根据一个类的全限定名来读取此类的二进制字节流到JVM内部，并存储在运行时内存区的方法区，然后将其转换为一个与目标类型对应的java.lang.Class对象实例 2. 验证 格式验证：验证是否符合class文件规范 语义验证：检查一个被标记为final的类型是否包含子类；检查一个类中的final方法是否被子类进行重写；确保父类和子类之间没有不兼容的一些方法声明（比如方法签名相同，但方法的返回值不同） 操作验证：在操作数栈中的数据必须进行正确的操作，对常量池中的各种符号引用执行验证（通常在解析阶段执行，检查是否可以通过符号引用中描述的全限定名定位到指定类型上，以及类成员信息的访问修饰符是否允许访问等 3. 准备 准备阶段是正式为类中定义的变量（即静态变量， 被static修饰的变量），并不是实例变量 分配内存并设置类变量初始值的阶段。在jdk8之后，类变量会随着Class对象一起存放在java堆中 4. 解析 解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程 5. 初始化 为静态变量赋值，执行static代码块等。 创建对象1. 在堆区分配对象需要的内存 分配的内存包括本类和父类的所有实例变量，但不包括任何静态变量 2. 对所有实例变量赋默认值 将方法区内对实例变量的定义拷贝一份到堆区，然后赋默认值 3. 执行实例初始化代码 初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法 4. 如果有类似于Child c = new Child()形式的c引用的话，在栈区定义Child类型引用变量c，然后将堆区对象的地址赋值给它 需要注意的是，每个子类对象持有父类对象的引用，可在内部通过super关键字来调用父类对象，但在外部不可访问]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql执行计划]]></title>
    <url>%2F2021%2F04%2F23%2Fmysql%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[mysql执行计划​ 在企业的应用场景中，为了知道优化SQL语句的执行，需要查看SQL语句的具体执行过程，以加快SQL语句的执行效率。 ​ 可以使用explain+SQL语句来模拟优化器执行SQL查询语句，从而知道mysql是如何处理sql语句的。 ​ 官网地址： https://dev.mysql.com/doc/refman/5.5/en/explain-output.html 1、执行计划中包含的信息 Column Meaning id The SELECT identifier select_type The SELECT type table The table for the output row partitions The matching partitions type The join type possible_keys The possible indexes to choose key The index actually chosen key_len The length of the chosen key ref The columns compared to the index rows Estimate of rows to be examined filtered Percentage of rows filtered by table condition extra Additional information id select查询的序列号，包含一组数字，表示查询中执行select子句或者操作表的顺序 id号分为三种情况： ​ 1、如果id相同，那么执行顺序从上到下 1explain select * from emp e join dept d on e.deptno = d.deptno join salgrade sg on e.sal between sg.losal and sg.hisal; ​ 2、如果id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 1explain select * from emp e where e.deptno in (select d.deptno from dept d where d.dname = 'SALES'); ​ 3、id相同和不同的，同时存在：相同的可以认为是一组，从上往下顺序执行，在所有组中，id值越大，优先级越高，越先执行 1explain select * from emp e join dept d on e.deptno = d.deptno join salgrade sg on e.sal between sg.losal and sg.hisal where e.deptno in (select d.deptno from dept d where d.dname = 'SALES'); select_type 主要用来分辨查询的类型，是普通查询还是联合查询还是子查询 select_type Value Meaning SIMPLE Simple SELECT (not using UNION or subqueries) PRIMARY Outermost SELECT UNION Second or later SELECT statement in a UNION DEPENDENT UNION Second or later SELECT statement in a UNION, dependent on outer query UNION RESULT Result of a UNION. SUBQUERY First SELECT in subquery DEPENDENT SUBQUERY First SELECT in subquery, dependent on outer query DERIVED Derived table UNCACHEABLE SUBQUERY A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query UNCACHEABLE UNION The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY) 12345678910111213141516171819202122232425262728--sample:简单的查询，不包含子查询和unionexplain select * from emp;--primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primaryexplain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;--union:若第二个select出现在union之后，则被标记为unionexplain select * from emp where deptno = 10 union select * from emp where sal &gt;2000;--dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响explain select * from emp e where e.empno in ( select empno from emp where deptno = 10 union select empno from emp where sal &gt;2000)--union result:从union表获取结果的selectexplain select * from emp where deptno = 10 union select * from emp where sal &gt;2000;--subquery:在select或者where列表中包含子查询explain select * from emp where sal &gt; (select avg(sal) from emp) ;--dependent subquery:subquery的子查询要受到外部表查询的影响explain select * from emp e where e.deptno in (select distinct deptno from dept);--DERIVED: from子句中出现的子查询，也叫做派生类，explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;--UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存 explain select * from emp where empno = (select empno from emp where deptno=@@sort_buffer_size); --uncacheable union:表示union的查询结果不能被缓存：sql语句未验证 table 对应行正在访问哪一个表，表名或者别名，可能是临时表或者union合并结果集 1、如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名 ​ 2、表名是derivedN的形式，表示使用了id为N的查询产生的衍生表 ​ 3、当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id type type显示的是访问类型，访问类型表示我是以何种方式去访问我们的数据，最容易想的是全表扫描，直接暴力的遍历一张表去寻找需要的数据，效率非常低下，访问的类型有很多，效率从最好到最坏依次是： system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 一般情况下，得保证查询至少达到range级别，最好能达到ref 12345678910111213141516171819202122232425262728293031--all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。explain select * from emp;--index：全索引扫描这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序explain select empno from emp;--range：表示利用索引查询的时候限制了范围，在指定范围内进行查询，这样避免了index的全索引扫描，适用的操作符： =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, BETWEEN, LIKE, or IN() explain select * from emp where empno between 7000 and 7500;--index_subquery：利用索引来关联子查询，不再扫描全表explain select * from emp where emp.job in (select job from t_job);--unique_subquery:该连接类型类似与index_subquery,使用的是唯一索引 explain select * from emp e where e.deptno in (select distinct deptno from dept); --index_merge：在查询过程中需要多个索引组合使用，没有模拟出来--ref_or_null：对于某个字段即需要关联条件，也需要null值的情况下，查询优化器会选择这种访问方式explain select * from emp e where e.mgr is null or e.mgr=7369;--ref：使用了非唯一性索引进行数据的查找 create index idx_3 on emp(deptno); explain select * from emp e,dept d where e.deptno =d.deptno;--eq_ref ：使用唯一性索引进行数据查找explain select * from emp,emp2 where emp.empno = emp2.empno;--const：这个表至多有一个匹配行，explain select * from emp where empno = 7369; --system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现 possible_keys ​ 显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; key ​ 实际使用的索引，如果为null，则没有使用索引，查询中若使用了覆盖索引，则该索引和查询的select字段重叠。 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; key_len 表示索引中使用的字节数，可以通过key_len计算查询中使用的索引长度，在不损失精度的情况下长度越短越好。 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; ref 显示索引的哪一列被使用了，如果可能的话，是一个常数 1explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; rows 根据表的统计信息及索引使用情况，大致估算出找出所需记录需要读取的行数，此参数很重要，直接反应的sql找了多少数据，在完成目的的情况下越少越好 1explain select * from emp; extra 包含额外的信息。 12345678910111213141516--using filesort:说明mysql无法利用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置explain select * from emp order by sal;--using temporary:建立临时表来保存中间结果，查询完成之后把临时表删除explain select ename,count(*) from emp where deptno = 10 group by ename;--using index:这个表示当前的查询时覆盖索引的，直接从索引中读取数据，而不用访问数据表。如果同时出现using where 表名索引被用来执行索引键值的查找，如果没有，表面索引被用来读取数据，而不是真的查找explain select deptno,count(*) from emp group by deptno limit 10;--using where:使用where进行条件过滤explain select * from t_user where id = 1;--using join buffer:使用连接缓存，情况没有模拟出来--impossible where：where语句的结果总是falseexplain select * from emp where empno = 7469;]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql缓存池]]></title>
    <url>%2F2021%2F03%2F21%2Fmysql%E7%BC%93%E5%AD%98%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[概述mysql中的重要组件buffer pool(缓存池)，为避免低效率频繁的IO操作，在内存中开辟一块空间为缓存池（默认设置128M，innodb_buffer_pool_size设置）,MYSQL相关操作先与缓存池交互。 组成结构buffer pool缓存页的大小和磁盘页的大小是一致的，都是16kb。 为了更好的管理这些在缓冲池中的缓存页，InnoDB为每一个缓存页都创建了一些所谓的控制信息。这些控制信息包括该页所属的表空间编号、页号、缓存页在缓冲池中的地址、链表节点信息、一些锁信息。 free链表mysql服务器系统启动后，首先申请Buffer Pool内存，然后将内存划分为若干个控制信息块和内存块，此时每个块尚未进行缓存数据，此时需要进行管理这些块，把所有的空闲的块通过链表关联到一起，这个链表称为 free链表（和STL中 内存池申请内存后使用链表管理方式类似），每一个缓存页对应的控制信息块都加入了这个链表中。 链表进行管理这些空闲块，那么关于链表的信息也需要进行存储，Innodb中，特意定义了一个称为 基节点 ，包含链表的头和尾以及节点个数信息。基节点所占有的内存不属于Buffer Pool中的，而是单独申请的一块内存，占用40字节的内存。 有了free链表之后，当磁盘中读取数据后，从free链表中获取一个空闲的块缓存数据，并将此块从free链表中移除，表示缓存已经被使用（读STL内存分配也是如此操作）。 flush链表如果修改了某个缓存页的数据，那么就会和磁盘上数据保持不一致，此时这个缓存页被称为脏页（dirty page）， 最简单的方式是如果出现脏页，那么立即同步到磁盘，频繁往写数据会严重影响程序的性能，so每次出现脏页，并不着急立即同步到磁盘，在后面某个节点进行同步（后详细叙述）；对于在缓存中出现的N多个脏页也需要我们进行管理，不然后面进行同步的时候找不到该同步哪些页，每次出现数据更新，成为脏页后这个页会被添加到一个flush链表中，flush链表构造和free链表差不多，也有个基节点保存链表信息：头节点，尾节点，个数等。 lru链表基于LRU算法(Least Recently Used)最近最少使用。 新数据插入到链表头部； 每当缓存命中（即缓存数据被访问），则将数据移到链表头部； 当链表满的时候，将链表尾部的数据丢弃。 遇到的问题全表扫描 当出现全表扫描时，InnoDB 会将该表的数据页全部从磁盘文件加载进缓存页中，这些缓存页会被加入到 LRU 链表中；这有可能导致需要淘汰许多频繁使用的缓存页。 预读 预读是 InnoDB 引擎的一个优化机制，当你从磁盘上读取某个数据页，InnoDB 可能会将与这个数据页相邻的其他数据页也读取到 Buffer Pool 中。 优化冷热分离 对数据进行冷热分离，将 LRU 链表分成两部分，一部分用来存放冷数据，也就是刚从磁盘读进来的数据，另一部分用来存放热点数据，也就是经常被访问到数据。 存放冷数据的区域占这个 LRU 链表的多少呢？这由参数 「innodb_old_blocks_pct」 控制，默认是 37%（约八分之三）。 当从磁盘读取数据页后，会先将数据页存放到 LRU 链表冷数据区的头部，如果这些缓存页在 1 秒之后被访问，那么就将缓存页移动到热数据区的头部；如果是 1 秒之内被访问，则不会移动，缓存页仍然处于冷数据区中。1 秒这个数值，是由参数 innodb_old_blocks_time 控制。 冷热分离其他优化 当一个缓存页处于热数据区域的时候，我们去访问这个缓存页，这个时候我们真的有必要把它移动到热点数据区域的头部吗？ 从代码的角度来看，将链表中的数据移动到头部，实际上就是修改元素的指针指向，这个操作是非常快的。但是为了安全起见，在修改链表的时候，我们需要对链表加上锁，否则容易出现并发问题。 当并发量大的时候，因为要加锁，会存在锁竞争，每次移动显然效率就会下降。因此 MySQL 针对这一点又做了优化，如果一个缓存页处于热数据区域，且在热数据区域的前 1/4 区域（注意是热数据区域的 1/4，不是整个链表的 1/4），那么当访问这个缓存页的时候，就不用把它移动到热数据区域的头部；如果缓存页处于热数据的后 3/4 区域，那么当访问这个缓存页的时候，会把它移动到热数据区域的头部。 生产调优 根据服务器配置，修改Buffer Pool 大小(避免频繁IO) 修改Buffer Pool 实例个数。（为了提高并发度，减少锁的竞争） 根据相关命令查询MYSQL状态信息（show engine innodb status;），判断冷数据区移动热数据区的频率，修改热数据区的比例（innodb_old_blocks_pct）]]></content>
      <categories>
        <category>MYSQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[垃圾回收算法]]></title>
    <url>%2F2020%2F09%2F01%2F%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[什么是垃圾 垃圾是指在运行程序中没有任何指针指向的对象,这个对象就是需要被回收的垃圾 如果不及时对内存中的垃圾及时清理,那么这个垃圾对象所占用的内存空间会一直保留到应用程序结束,被保留的空间无法被其他对象使用。甚至可能导致内存溢出。 引用计数算法对于一个对象,只要有任何一个对象引用了A,则A的引用计数器就加1;当引用失效时,引用计数器就减1。只要对象A的引用计数器的值为0,即表示对象A不可能再被使用,可进行回收 优点:实现简单,垃圾对象便于表示;判定效率高,回收没有延迟行性。 缺点: 需要单独的字段存储计数器,这样的做法增加了存储的开销 每次赋值都需要更新计数器,伴随着加法和减法的操作,这增加了时间开销 引用计数器有一个严重的问题,即无法处理循环引用的情况。这是一条致命缺陷,导致在java的垃圾回收器中没有使用这类算法。会存在内存泄漏问题。 可达性分析算法基本思路 可达性分析算法是以根对象集合(GCRoots)为起始点,按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达 使用可达性分析算法后,内存中存活的对象都会被根对象集合直接或间接连接着,搜索所走过的路劲称为引用链 如果目标对象没有任何引用链相连,则是不可达,意味着该对象已经死亡,可以标记为死亡对象 在可达性分析算法中,只有能被根对象集合直接或间接连接的对象才是存活对象 GC Roots包括以下几类元素 虚拟机栈引用的对象(比如各个线程被调用的方法中使用的参数,局部变量等) 本地方法栈内JNI(通常说的本地方法)引用的对象 方法区中类静态属性所引用的对象 在方法区中常量引用的对象，譬如字符串常量池里的引用 所有被同步锁synchronized持有的对象 JAVA虚拟机内部的引用 反映java虚拟机内部情况的JMXBean,JVMTI中注册的回调,本地代码缓存等 小技巧 由于Root采用栈方式存放变量和指针,所以如果一个指针,它保存了堆内存里面的对象,但是自己又不存放堆内存里面,那它就是一个Root 对象的finalization机制即使在可达性分析算法中判定为不可达的对象，也不是“非死不可”的，这时候它们暂时还处于“缓 刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没 有与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是 否有必要执行finalize()方法。假如对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用 过，那么虚拟机将这两种情况都视为“没有必要执行”。 当垃圾回收器发现没有引用指向一个对象,即:垃圾回收此对象之前,总会先调用这个对象的finalize()方法 GC Root 分析工具先把生成程序dump文件,具体分析工具有Jprofiler,MAT dump文件生成JVM生成dump文件一般有两种方式 一、 出现OOM时自动生成堆dumpJVM启动命令增加两个参数:-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=/home/app/dumps/ 二、人工通过执行指令，直接生成当前JVM的dump文件例如：jmap -dump:format=b,file=/home/app/testdump.hprof 6218其中6218是JVM的当前进程号 垃圾回收算法分代收集理论部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分为: 新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集。 老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集。目前只有==CMS收集器==会有单 独收集老年代的行为。另外请注意“Major GC”这个说法现在有点混淆，在不同资料上常有不同所指， 读者需按上下文区分到底是指老年代的收集还是整堆收集。 混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有G1收 集器会有这种行为。 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。 标记-清除算法(Mark-Sweep)标记: Collector从引用根节点开始遍历,标记为所有被引用的对象。一般是在对象的Header中记录为可达对象 清除: Collector对堆内存从头到尾进行线性的遍历,如果发现某个对象在其Header中没有标记为可达对象,则将其回收 缺点: 效率不算高(递归方式遍历) 在进行GC的时候,需要停止整个应用程序,导致用户体验差 这种方式清理出来的空闲内存是不连续的,产生内存碎片。需要维护一个空闲列表 复制算法将活着的内存空间分位两块,每次只使用其中一块,在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中,之后清除正在使用内存块中的所有对象,交换两个内存的角色,最后完成垃圾回收。 优点: 没有标记和清除过程,实现简单,运行高效 复制过去以后保证空间的连续性,不会出现碎片问题 缺点: 此算法的缺点也是很明显的,就是需要两倍的空间内存。 对于G1这种拆分为大量region的GC,复制而不是移动,意味着GC需要维护region之间对象引用关系,不管内存占用或者时间开销也不小 适合垃圾对象很多,存活对象很少的场景;例如:新生代中的Survior0和Surivor1 标记-压缩算法第一阶段和标记清除算法一样,从根节点开始标记所有被引用对象。第二阶段将所有的存活对象压缩到内存的一端,按顺序排放。之后,清理边界外所有的空间. 优点: 消除了标记-清除算法当中,内存区域分散的缺点,我们需要给新对象分配内存是,JVM只需要持有一个内存的起始地址即可。 消除了复制算法当中,内存减半的高额代价 缺点: 从效率上来说,标记-整理算法要低于复制算法 移动对象的同事,如果对象被其他对象引用,则还需要调整引用的地址 移动过程中,需要全程暂停用户应用程序。即:STW 总结 增量收集算法和分区算法System.gc()提醒jvm垃圾回收器执行gc,但是不确定是否马上执行gc System.runFinalization(); 内存泄漏举例单例模式 一些提供close的资源未关闭导致内存泄漏 引用 强引用 强引用所指向的对象在任何时候都不会被系统回收,虚拟机宁愿抛出OOM异常,也不会回收强引用所指向对象。可能导致内存泄漏 软引用 软引用是用来描述一些还有用,但非必需的对象。只被软引用关联着的对象,在系统将要发生内存溢出异常前,会把这些对象列进回收范围之中进行第二次回收,如果这次回收还没有足够的内存,才会抛出内存溢出异常。 通常用来实现内存敏感的缓存。比如:高速缓存 SoftReference sf = new SoftReference(obj) 弱引用 在系统GC时,只要发现弱引用,不管系统堆空间使用是否充足,都会回收掉只被弱引用关联的对象 WeakReference sf = new WeakReference(obj) 弱引用对象与软引用对象最大的不同就在于,当GC在进行回收时,需要通过算法检查是否回收软引用对象,而对于弱引用对象,GC总是回收。弱引用对象更容易更快被GC回收。 ThreadLocal 中 ThreadLocalMap的key使用弱引用 虚引用 为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如能在这个对象被收集器回收时收到一个系统通知。 DirectBuffer(直接内存)有用到]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>垃圾回收算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-排序算法]]></title>
    <url>%2F2018%2F11%2F05%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法 插入排序（直接插入；折半插入；希尔插入） 选择排序（简单选择排序；堆排序） 交换排序 (冒泡排序；快速排序) 归并排序 基数排序 外部排序 冒泡排序两两比较相邻元素，每趟冒泡的结果是把序列中的最大元素放到了序列中的最终位置123456789101112public void bubbleSort(int[] array)&#123; int temp; for (int i = 0; i &lt; array.length ; i++) &#123; for (int j = 0; j &lt; array.length-1-i ; j++) &#123; if(array[j]&lt;array[j+1])&#123; temp = array[j]; array[j] = array[j+1]; array[j+1] = temp; &#125; &#125; &#125;&#125; 快速排序快速排序是冒泡排序的一种改进。基本思想是:通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另一部分的所有数据小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，已达到整个序列变成有序序列。 123456789101112131415161718192021222324public void quickSort(int[] array,int low,int high)&#123; if(low&lt;high)&#123; int index = getIndex(array,low,high); quickSort(array,low,index-1); quickSort(array,index+1,high); &#125; &#125; public int getIndex(int[] array,int low,int high)&#123; int temp = array[low]; while (low&lt;high)&#123; while(low&lt;high &amp;&amp; array[high]&gt;temp)&#123; high--; &#125; array[low] = array[high]; while (low&lt;high &amp;&amp; array[low]&lt;temp)&#123; low++; &#125; array[high] = array[low]; &#125; array[low] = temp; return low; &#125; 直接插入排序基本思想：每一步将一个待排序的数据插入到前面已经排好序的有序序列中，直到插完所有元素为止。 12345678910public void insertSort(int[] array)&#123; int j; for (int i = 1; i &lt;array.length ; i++) &#123; int temp = array[i]; for (j = i-1; j&gt;=0 &amp;&amp; temp&lt;array[j] ; j--) &#123; array[j+1] = array[j]; &#125; array[j+1] = temp; &#125; &#125; 希尔排序思想和直接插入类似，只是引入增量的概念，又称缩小增量排序 123456789101112public void shellSort(int[] array)&#123; int j; for(int gap = array.length/2;gap&gt;0;gap/=2)&#123; for(int i = gap;i&lt;array.length;i++)&#123; int temp = array[i]; for(j = i-gap;j&gt;=0&amp;&amp;temp&lt;array[j];j-=gap)&#123; array[j+gap] = array[j]; &#125; array[j+gap] = temp; &#125; &#125; &#125; 选择排序假设排序表为L[1…n],第i趟排序即从L[i…n]中选择关键字最小的元素与L(i)交换，每一趟排序可以确认一个元素的最终位置,这样经过n-1趟排序就可使整个排序表有序。 12345678910111213141516171819public void selectSort(int[] array)&#123; int minValue; int minIndex; for (int i = 0; i &lt; array.length; i++) &#123; minValue = array[i]; minIndex = i; for (int j = i+1; j &lt;array.length ; j++) &#123; if(minValue&gt;array[j])&#123; minValue = array[j]; minIndex = j; &#125; &#125; //交换最小值 if(minValue!=array[i])&#123; array[minIndex] = array[i]; array[i] = minValue; &#125; &#125; &#125; 归并排序采用分治的思想，分成一些小问题递归求解。将数组元素一个个分成独立元素，再两两合并，以此类推得到完整的有序序列。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void mergeSortTest()&#123; int[] array = &#123;10,9,8,7,6,5&#125;; int[] temp = new int[array.length]; mergeSort(array,0,array.length-1,temp); System.out.println(Arrays.toString(array)); &#125; public void mergeSort(int[] array,int left,int right,int[] temp)&#123; if(left&lt;right)&#123; int mid = (left+right)/2; mergeSort(array,left,mid,temp); mergeSort(array,mid+1,right,temp); merge(array,left,mid,right,temp); &#125; &#125; public void merge(int[] array,int left ,int mid,int right,int[] temp)&#123; int i = left; int j = mid+1; int t = 0; while (i&lt;=mid &amp;&amp; j&lt;=right)&#123; if(array[j]&lt;array[i])&#123; temp[t] = array[j]; j++; &#125;else&#123; temp[t] = array[i]; i++; &#125; t++; &#125; while (i&lt;=mid)&#123; temp[t] = array[i]; i++; t++; &#125; while (j&lt;=right)&#123; temp[t] = array[j]; j++; t++; &#125; //合并 t = 0 ; while (left&lt;=right)&#123; array[left] = array[t]; left++; t++; &#125; &#125; 基数排序基数排序(Radix Sort)是桶排序的扩展，它的基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是：将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 1234567891011121314151617181920212223242526272829303132333435public void radixSortTest(int[] array)&#123; //求最大值 int maxValue = array[0]; for(int value:array)&#123; if(value&gt;maxValue)&#123; maxValue = value; &#125; &#125; //求最大值位数 int digit = (maxValue+&quot;&quot;).length(); //桶数量 int[][] buckets = new int[10][array.length]; //每个桶计数 int[] bucketNum = new int[10]; for(int i = 0,n = 1;i&lt;digit;i++,n*=10)&#123; //元素放入桶中 for(int j=0;j&lt;array.length;j++)&#123; int digitValue = array[j]/n%10; buckets[digitValue][bucketNum[digitValue]] = array[j]; bucketNum[digitValue]++; &#125; int index = 0; //将元素放入回数组中 for (int k = 0; k &lt;bucketNum.length ; k++) &#123; if(bucketNum[k]!=0)&#123; for(int l = 0;l&lt;bucketNum[k];l++)&#123; array[index++] = buckets[k][l]; &#125; &#125; bucketNum[k] = 0; &#125; &#125; &#125; 排序算法比较]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[过滤器ip白名单]]></title>
    <url>%2F2018%2F10%2F08%2F%E8%BF%87%E6%BB%A4%E5%99%A8ip%E7%99%BD%E5%90%8D%E5%8D%95%2F</url>
    <content type="text"><![CDATA[Filter中注入Bean失败在写这个过滤器的时候遇到个问题,Bean注入失败，为空，以前也没有注意到。 原理其实Spring中，web应用启动的顺序是：listener-&gt;filter-&gt;servlet，先初始化listener，然后再来就filter的初始化，再接着才到我们的dispathServlet的初始化，因此，当我们需要在filter里注入一个注解的bean时，就会注入失败，因为filter初始化时，注解的bean还没初始化，没法注入。 解决方式解决方式有好几种我用的是手动getBean的方式12ApplicationContext ac1 = WebApplicationContextUtils.getRequiredWebApplicationContext(ServletContext sc); ac1.getBean(&quot;beanId&quot;); 这里getBean内容注意大小写，经常因为没注意没获取到bean。 获取登录ip12345678910111213141516171819202122232425/** * 通过HttpServletRequest返回IP地址 * @param request HttpServletRequest * @return ip String * @throws Exception */ public String getIpAddr(HttpServletRequest request) throws Exception &#123; String ip = request.getHeader(&quot;x-forwarded-for&quot;); if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;Proxy-Client-IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;WL-Proxy-Client-IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;HTTP_CLIENT_IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;HTTP_X_FORWARDED_FOR&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); &#125; return ip; &#125;]]></content>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins初步使用]]></title>
    <url>%2F2018%2F10%2F05%2Fjenkins%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[linux环境下安装jenkins1.第一种是网上下载jenkins war包拷到/webapp目录下2.第二种是在线安装,通过yum方式安装下载sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.reposudo rpm –import https://jenkins-ci.org/redhat/jenkins-ci.org.keysudo yum install jenkins 启动jenkinsservice jenkins start 注意:这里最好修改jenkins默认端口号8080，以防冲突vi /etc/sysconfig/jenkins查找/JENKINS_PORT，修改JENKINS_PORT=”8080”，默认为“8080”，我修改为了9999## 访问jenkins地址:http://ip:修改后的端口号第一次登录是需要解锁，依据提示的路径,拷贝相应的密码到浏览器输入框。之后提示安装自定义插件还是推荐插件，此处我选择推荐插件注意：这里，可能是由于网络的原因，我的一些插件迟迟下载不下来，页面卡死在下载插件那里，我就强制重启jenkins。ps -ef|grep jenkins,找出相应的jenklins进程，杀死进程：kill 进程号，之后重启jenkins,service jenkins start，重新访问，便可以进入到主界面，依据提示设置用户名密码那些。 后续jenkins各项操作陆续更新。。。。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>自动化部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq延迟队列简单实用]]></title>
    <url>%2F2018%2F09%2F26%2Frabbitmq%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97%E7%AE%80%E5%8D%95%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[&nbsp; &nbsp; &nbsp; &nbsp;之前也没有具体研究过rabbitmq延迟队列的实现，前段时间在写短信提醒用户支付订单这个需求的时候，发现了一些问题。现有的商城系统，订单取消定时器是5分钟跑一次，这样就造成了会有5分钟的时间误差，前端给用户的提示以及后续的操作都会有影响。而且这种定时器一直跑着还是挺消耗系统资源的，增加数据库压力 &nbsp; &nbsp; &nbsp; &nbsp;然后也是一直查阅资料看看有什么更好的解决方案，看到这本《Rabbitmq实战指南》写还的挺好的，通俗易懂，里面也简单介绍了延迟队列。 什么是延迟队列&nbsp; &nbsp; &nbsp; &nbsp;延迟队列存储的对象肯定是对应的延迟消息，所谓”延迟消息”是指当消息被发送以后，并不想让消费者立即拿到消息，而是等待指定时间后，消费者才拿到这个消息进行消费。其实，AMQP协议，以及RabbitMQ本身没有直接支持延迟队列的功能，但是可以通过TTL和DLX模拟出延迟队列的功能。 过期时间TTLTTL(Time To Live),即过期时间,RabbitMQ可以对消息和队列设置过期时间。消息在队列中的生存时间一旦超过了设置的TTL值，就会变为死信。 设置消息的TTL1234byte[] messageBodyBytes = &quot;Hello, world!&quot;.getBytes();AMQP.BasicProperties properties = new AMQP.BasicProperties();properties.setExpiration(&quot;60000&quot;);//设置消息的过期时间为60秒channel.basicPublish(&quot;my-exchange&quot;, &quot;routing-key&quot;, properties, messageBodyBytes); 设置队列的TTL123Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-expires&quot;, 1800000);channel.queueDeclare(&quot;myqueue&quot;, false, false, false, args); DLX死信队列1234567891011Dead Letter Exchanges,可以称为死信交换器channel.exchangeDeclare(&quot;exchange_delay_begin&quot;, &quot;direct&quot;, true);channel.exchangeDeclare(&quot;exchange_delay_done&quot;, &quot;direct&quot;, true);Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-dead-letter-exchange&quot;, &quot;exchange_delay_done&quot;);channel.queueDeclare(&quot;queue_delay_begin&quot;, true, false, false, args);channel.queueDeclare(&quot;queue_delay_done&quot;, true, false, false, null);channel.queueBind(&quot;queue_delay_begin&quot;, &quot;exchange_delay_begin&quot;, &quot;delay&quot;);channel.queueBind(&quot;queue_delay_done&quot;, &quot;exchange_delay_done&quot;, &quot;delay&quot;); 这些内容我写的还是比较简单，后续会进一步的完善。建议阅读官方文档http://www.rabbitmq.com/ttl.html#per-queue-message-ttl，或者上面提到的《RabbitMQ实战指南》,整个延迟队列的实现过程还是比较简单的，之后会把完整的代码贴出来。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[和喜欢的一切在一起]]></title>
    <url>%2F2018%2F09%2F24%2F%E5%92%8C%E5%96%9C%E6%AC%A2%E7%9A%84%E4%B8%80%E5%88%87%E5%9C%A8%E4%B8%80%E8%B5%B7%2F</url>
    <content type="text"><![CDATA[浮光再潋滟，淌不过流年。但纵使往事如烟，依然感谢你有缘在我生命中昙花一现。 这世界最美妙最浪漫的事就是做着自己喜欢的事还可以养活自己。 忘了谁说过，陪伴是最长情的告白。但我想说，守护使最沉默的陪伴。亲情，友情，爱情，但凡是感情想要长久都一样，就两句话：别听对方说什么，只看对方做什么；别在意对方没做什么，只在意对方付出了什么。这世上没人欠你什么，你也不欠别人什么，一切凭心。所谓珍惜，不是小心翼翼，而是自然反应。 也许故事没有那么多失忆，但柳暗花明的香味依旧最袭人。 北漂三年，最害怕行李箱的万向轮龇着地面时发出的哗啦。 但如果命运这么好掌握，那就不叫命运了 东西坏了，别想到丢，试试看能不能修。我们都一样，拥有的东西很少，别等到什么都没了，才学会哭。 活在一种看得见未来的生活里是很无趣的，尽管我知道每个人都有一个共同的结局是死亡，但如果我们活着的每一天都不能有所发现，没有未知和好奇，而只是机械地重复同样的事情，那等于我们已经死了。 在这个散乱的世界，每个人都在表达自己，却独独少了那位坐在对面,认真聆听，静静端详着你的听众。 许多人来来去去，相聚又别离。也有人匆匆逃离，这一个人的北京。]]></content>
      <categories>
        <category>杂书</category>
      </categories>
      <tags>
        <tag>读后感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo实现搜索,评论功能]]></title>
    <url>%2F2018%2F09%2F24%2Fhexo%E5%AE%9E%E7%8E%B0%E6%90%9C%E7%B4%A2-%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"></content>
      <categories>
        <category>hexo博客实现</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
</search>
